{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from utils import buit_eval_model, load_json, clear_folder, list_folders\n",
    "import os\n",
    "from model import MAE\n",
    "import numpy as np\n",
    "from utils_cam import web_cam, node_json, split_json, visualize\n",
    "from utils import video_clip_procedure, video_clip_stream, video_process_stream\n",
    "model_path = 'D:\\google drive\\MAE Bs PJ\\state_dict\\epoch 3-4200 weight.pt'\n",
    "CHECKPOINT_PATH = 'checkpoint.tar'\n",
    "\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "step = checkpoint['step']\n",
    "mean = checkpoint['mean']\n",
    "std = checkpoint['std']\n",
    "model = buit_eval_model(model_path)\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c6c171214e4e059fd5da711e4fee27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dir = r'data\\phonetic notation'\n",
    "output = r'features\\feature-phonetic notation2.json'\n",
    "class_features = {}\n",
    "sample_num  = 100\n",
    "for index in tqdm(range(len(list_folders(dataset_dir)))):\n",
    "    try:\n",
    "        prediction_list = []\n",
    "        for _ in range(sample_num):\n",
    "            prediction, class_name = video_process_stream(model=model,\n",
    "                                dataset_dir=dataset_dir,\n",
    "                                index=index,\n",
    "                                mean=mean,\n",
    "                                std=std,\n",
    "                                augment=True)\n",
    "            prediction_list.append(prediction.squeeze().tolist())\n",
    "\n",
    "        class_features[f'{class_name}'] = prediction_list\n",
    "        with open(output, 'w') as f:\n",
    "            json.dump(class_features, f, indent=4, ensure_ascii=False)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6270fd45f7bb4f0db2a4f6e077a368e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dir = 'data\\expriment-phonetic notation'\n",
    "output = 'features\\expriment-phonetic notation2.json'\n",
    "class_features = {}\n",
    "sample_num  = 10\n",
    "for index in tqdm(range(len(list_folders(dataset_dir)))):\n",
    "    try:\n",
    "        prediction_list = []\n",
    "        for i in range(sample_num):\n",
    "            prediction, class_name = video_process_stream(model=model,\n",
    "                                dataset_dir=dataset_dir,\n",
    "                                index=index,\n",
    "                                mean=mean,\n",
    "                                std=std,\n",
    "                                augment=False,\n",
    "                                i=i)\n",
    "            prediction_list.append(prediction.squeeze().tolist())\n",
    "\n",
    "        class_features[f'{class_name}'] = prediction_list\n",
    "        with open(output, 'w') as f:\n",
    "            json.dump(class_features, f, indent=4, ensure_ascii=False)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 10\n",
    "video_dir = 'video'\n",
    "video_path_list = [os.path.join(video_dir,i) for i in os.listdir(video_dir)]\n",
    "class_name_list = [os.path.basename(i).replace('.mp4', '') for i in video_path_list]\n",
    "class_name = class_name_list[index]\n",
    "\n",
    "clear_folder(rf'dataset\\{class_name}\\{class_name}')\n",
    "save_folder = os.path.join('dataset', class_name)\n",
    "input_video = os.path.join(save_folder, 'output.mp4')\n",
    "input_json  = os.path.join(save_folder, 'nodes.json')\n",
    "time_mark_path=os.path.join(save_folder, 'time mark.json')\n",
    "output_folder = os.path.join(save_folder, class_name)\n",
    "os.makedirs(save_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buit_eval_model(model_path)\n",
    "video_path, output_path = video_path_list[index], rf'dataset\\{class_name}\\output.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# video clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clip_procedure(video_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clip_stream('video', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# video process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_json(video_path, save_folder, show=True)\n",
    "split_json(input_json, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = rf'dataset\\{class_name}\\{class_name}\\segment.json'\n",
    "visualize(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_json(json_path, mean, std).to('cuda')\n",
    "prediction = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('feature.json', 'r') as f:\n",
    "    class_features = json.load(f)\n",
    "class_features[f'{class_name}'] = prediction.squeeze().tolist()\n",
    "with open('feature.json', 'w') as f:\n",
    "    json.dump(class_features, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reset class_future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_features = {}\n",
    "with open('feature.json', 'w') as f:\n",
    "    json.dump(class_features, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_features = {}\n",
    "with open('expriment.json', 'w') as f:\n",
    "    json.dump(class_features, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('feature.json', 'r') as f:\n",
    "    class_features = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v11-4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
