{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "from lightly.models import utils\n",
    "\n",
    "from model import MAE\n",
    "from tqdm.auto import tqdm, trange\n",
    "import os\n",
    "model_path = 'D:\\google drive\\MAE Bs PJ\\state_dict\\epoch 3-4200 weight.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit = torchvision.models.vit_b_16(weights=None)\n",
    "pretrained_model = MAE(vit, 64, 80)\n",
    "pretrained_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_class):\n",
    "        super(ViT, self).__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "                    pretrained_model.backbone,\n",
    "                    nn.Linear(768, num_class),\n",
    "                    nn.Softmax(dim=1)\n",
    "                )\n",
    "        self.out_dim = 80\n",
    "\n",
    "    def forward(self, images):\n",
    "        batch_size = images.shape[0]\n",
    "        seq_length = images.shape[1]\n",
    "        images = images.reshape((batch_size, seq_length, self.out_dim))\n",
    "        x = self.backbone(images)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (backbone): Sequential(\n",
       "    (0): MAEBackbone(\n",
       "      (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (encoder): MAEEncoder(\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (layers): Sequential(\n",
       "          (encoder_layer_0): EncoderBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (self_attention): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (encoder_layer_1): EncoderBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (self_attention): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (encoder_layer_2): EncoderBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (self_attention): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (encoder_layer_3): EncoderBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (self_attention): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (encoder_layer_4): EncoderBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (self_attention): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (encoder_layer_5): EncoderBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (self_attention): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (encoder_layer_6): EncoderBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (self_attention): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (encoder_layer_7): EncoderBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (self_attention): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (encoder_layer_8): EncoderBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (self_attention): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (encoder_layer_9): EncoderBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (self_attention): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (encoder_layer_10): EncoderBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (self_attention): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (encoder_layer_11): EncoderBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (self_attention): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (heads): Sequential(\n",
       "        (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=80, out_features=768, bias=True)\n",
       "    )\n",
       "    (1): Linear(in_features=768, out_features=15, bias=True)\n",
       "    (2): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "batch_size = 16\n",
    "Epochs = 20\n",
    "num_classes = len(os.listdir(r'D:\\MaE fine tune\\DataSet\\train section'))\n",
    "\n",
    "model = ViT(pretrained_model, num_class = num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "model = model.to('cuda')\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = 'checkpoint.tar'\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "step = checkpoint['step']\n",
    "mean = checkpoint['mean']\n",
    "std = checkpoint['std']\n",
    "total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import normalize_data, Node_Dataset, get_time\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "data_folder = r'DataSet\\train section'\n",
    "test_folder = r'DataSet\\test section'\n",
    "\n",
    "dataset = Node_Dataset(data_folder, mean, std)\n",
    "trainloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = Node_Dataset(test_folder, mean, std)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\MaE fine tune\\wandb\\run-20231028_003430-msdjug9t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gethation-rx/MaE%20fine%20tune/runs/msdjug9t' target=\"_blank\">batch_size: 16-2</a></strong> to <a href='https://wandb.ai/gethation-rx/MaE%20fine%20tune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gethation-rx/MaE%20fine%20tune' target=\"_blank\">https://wandb.ai/gethation-rx/MaE%20fine%20tune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gethation-rx/MaE%20fine%20tune/runs/msdjug9t' target=\"_blank\">https://wandb.ai/gethation-rx/MaE%20fine%20tune/runs/msdjug9t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    project='MaE fine tune',\n",
    "    name=f'batch_size: {batch_size}-2',\n",
    "    config={\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"architecture\": \"ViT\",\n",
    "        \"dataset\": \"customer\",\n",
    "        \"epochs\": Epochs,\n",
    "        \"mean\": mean,\n",
    "        \"std\": std})\n",
    "config = wandb.config\n",
    "\n",
    "wandb.watch(model)\n",
    "epoch = 0\n",
    "step = 0\n",
    "total_loss = 0\n",
    "total_accuracy = 0\n",
    "model_savepath = f'D:\\MaE fine tune\\state_dict'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import video_show, train_step, Evaluate, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9da5a13ae1348cb86cc6d50223354ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 48.56214904785156,\"accuracy\": 10.0%|\"test_loss\": 2.661360263824463,\"evaluative_accuracy\": 13.33%\n",
      "epoch: 00, time: 8:35:19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637cb824f72d48cfbcf639558dab74f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 47.526123046875,\"accuracy\": 17.0%|\"test_loss\": 2.546891927719116,\"evaluative_accuracy\": 33.33%\n",
      "epoch: 01, time: 8:35:40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2c31adb5e54c3e83c203588c3f9077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 44.739131927490234,\"accuracy\": 37.0%|\"test_loss\": 2.511406183242798,\"evaluative_accuracy\": 26.67%\n",
      "epoch: 02, time: 8:36:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de81634743d44ec786f225cb66c941d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 43.4141960144043,\"accuracy\": 45.0%|\"test_loss\": 2.4380621910095215,\"evaluative_accuracy\": 40.0%\n",
      "epoch: 03, time: 8:36:22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0837a80e3d4afcb0e818c1def6e5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 42.34962844848633,\"accuracy\": 49.0%|\"test_loss\": 2.4108965396881104,\"evaluative_accuracy\": 40.0%\n",
      "epoch: 04, time: 8:36:43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa40c5fd6a2f43d8bfdc5537bb72e78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 42.19560241699219,\"accuracy\": 51.0%|\"test_loss\": 2.323470115661621,\"evaluative_accuracy\": 53.33%\n",
      "epoch: 05, time: 8:37:4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff00f2c30dd49dca676b4b0e36c9f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 40.883453369140625,\"accuracy\": 58.0%|\"test_loss\": 2.3269786834716797,\"evaluative_accuracy\": 53.33%\n",
      "epoch: 06, time: 8:37:39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fceea379c334055a5fd896fb1bf0760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 39.62763214111328,\"accuracy\": 63.0%|\"test_loss\": 2.2648561000823975,\"evaluative_accuracy\": 60.0%\n",
      "epoch: 07, time: 8:38:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b721dc88d4f444a9385e2e63b06d51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 39.05430603027344,\"accuracy\": 69.0%|\"test_loss\": 2.172774314880371,\"evaluative_accuracy\": 66.67%\n",
      "epoch: 08, time: 8:38:21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5afc715898e147fe9b712e540796ad86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 38.248050689697266,\"accuracy\": 71.0%|\"test_loss\": 2.1071667671203613,\"evaluative_accuracy\": 73.33%\n",
      "epoch: 09, time: 8:38:42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713b86360f2d46dfbd4c673f67eb67f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 38.38497543334961,\"accuracy\": 70.0%|\"test_loss\": 2.1434545516967773,\"evaluative_accuracy\": 73.33%\n",
      "epoch: 10, time: 8:39:4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94ba8f798bd4b938ec3da0318a0526e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 38.09982681274414,\"accuracy\": 71.0%|\"test_loss\": 2.091933012008667,\"evaluative_accuracy\": 73.33%\n",
      "epoch: 11, time: 8:39:25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cfc7bd506bc46f786388fd52966046b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 37.46954345703125,\"accuracy\": 76.0%|\"test_loss\": 2.106869697570801,\"evaluative_accuracy\": 73.33%\n",
      "epoch: 12, time: 8:39:46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1088d8983ade489fbdd8ca5aa4cd1da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 38.90101623535156,\"accuracy\": 67.0%|\"test_loss\": 2.1690118312835693,\"evaluative_accuracy\": 73.33%\n",
      "epoch: 13, time: 8:40:7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122ed35ded3d451ba40538bc21c8d1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 37.56167984008789,\"accuracy\": 74.0%|\"test_loss\": 2.0912442207336426,\"evaluative_accuracy\": 73.33%\n",
      "epoch: 14, time: 8:40:28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25eb19cbca048b6a663c669e4313474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 37.34629821777344,\"accuracy\": 76.0%|\"test_loss\": 2.077385902404785,\"evaluative_accuracy\": 80.0%\n",
      "epoch: 15, time: 8:40:50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8248bb9d9a6842649758dfd540233f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 37.54411315917969,\"accuracy\": 73.0%|\"test_loss\": 2.113452196121216,\"evaluative_accuracy\": 73.33%\n",
      "epoch: 16, time: 8:41:26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503fd1e72e9146bb8b31440d0a0d8b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 37.57820510864258,\"accuracy\": 73.0%|\"test_loss\": 2.046360492706299,\"evaluative_accuracy\": 80.0%\n",
      "epoch: 17, time: 8:42:23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d4904472d04af3bd134b3bfa5b8418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 36.50830078125,\"accuracy\": 79.0%|\"test_loss\": 2.0781543254852295,\"evaluative_accuracy\": 73.33%\n",
      "epoch: 18, time: 8:42:52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19f4d44c7584ccc8c22c84889e60683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss\": 36.48641586303711,\"accuracy\": 79.0%|\"test_loss\": 2.083428382873535,\"evaluative_accuracy\": 73.33%\n",
      "epoch: 19, time: 8:43:13\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(Epochs):\n",
    "    for i, (batch, target) in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
    "\n",
    "        loss, accuracy = train_step(model,\n",
    "                    criterion,\n",
    "                    batch,\n",
    "                    target,\n",
    "                    optimizer,\n",
    "                    num_classes=num_classes)\n",
    "        total_loss += loss\n",
    "        total_accuracy += accuracy\n",
    "        with torch.no_grad():\n",
    "            evaluative_loss, evaluative_accuracy = Evaluate(model, criterion, testloader, num_classes)\n",
    "\n",
    "        wandb.log({\"accuracy\": accuracy,\"evaluative_accuracy\": evaluative_accuracy})\n",
    "    total_accuracy = total_accuracy//(i+1)\n",
    "    torch.save(model.state_dict(),os.path.join(model_savepath, f'2epoch-{epoch+1}weight.pt'))\n",
    "    print(f'train_loss\": {total_loss},\"accuracy\": {total_accuracy}%|\"test_loss\": {evaluative_loss},\"evaluative_accuracy\": {evaluative_accuracy}%')\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    print(f'epoch: {epoch:>02}, time: {get_time()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v11-4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
